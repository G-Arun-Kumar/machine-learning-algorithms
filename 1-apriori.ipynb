{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8617792,"sourceType":"datasetVersion","datasetId":5158113}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Association Rule Learning Intuition\n\n**'People who bought also bought'**. We would have come accross this statement or information when we buy in e-commerce websites like Flipkart or amazon. Yes. we are going to see today a topic about **recommender systems**. It's called as **association rule learning**.\n\nWe will see this via. a story.\n\nA **convenience store** did some analytics around the products that people were purchasing. They analyzed thousands and thousands and thousands of products. **Surprisingly, a peculiar commanilities between two different products** are found.\nThey are **diapers & beers**. Very peculiar ain't it?..\n\n**Deep into the story** - The husbands who are out of work and on their return to home, the wives calls them to buy diapers when they come home. And husbands after buying the diapers, they tend to buy beers before they move on to billing. This is the reason for these two products to get sold more.\n\nSo, In short, this algorithm helps to give the rule to buy two things with high statistical value. The products if bought together, will give good sales to business person.\n\nIn other words, it helps to identify the two best products that can be bought together using the rule of statistical approch and not just with speculation. business people will use criteria to increase sales of a product or do market by giving the ads to motivate the customer to buy this product.\n\n**People who bought something also bought something, people who watched also watched something, people who did something also did something** anything could be.\n\nAnd this ideally shouldn't stop **recommending with one other product alone. It can also use more than one. It can be three or four or five and so on**.\n\nThere are many types of algorithms available on association rule learning. Of which we will see two main types. They are,\n\n1. Apriori\n\n2. Eclat","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Apriori Intuition\n\nThere are some potential rules to recommend a product.\nApriori comes in three parts. They are,\n\n1. Support\n\n2. Confidence\n\n3. Lift\n\nLet's see everything in detail. The below diagram depicts the users who watched certain movies. There are people who watched movies1,2,3,4. There are people who watched both movies 1 and 4. There are people who watched both movies 1 and 3.\nPeople who both 2 and 4. People who watched 1 and 2 and so on and on and on... there are several combinations like this.\nSo, to apply the rule to recommend viewers to buy the other movie, the above algorithm is applied.\n\n**Support** - It's very similar to naive bayes algorithm. It is used for **movie recommendation**. **Support for movie M** is defined as,\n\n**Support(M) = No. of user watchlist containing M / Total no. of users.**\n\nThe above statement is as simple as the no. of users who watched a particular movie divided by the total no. of users.\n\n**Confidence(M) = No. of users watchlist containing M1 and M2 / No. of users watchlist containing M1**.\n\nThe above statement is nothing but, if suppose a movie M1 is watched by 50 users. And the same 50 users also watched movie M2 is 20. Then **confidence** is 20/50 = 2.5\n\n**Lift(M1->M2) = Confidence(M1->M2) / Support(M2)**\n\nThe above statement clearly defines. It's just the confidence/support.\n\nLet's see the step by step approach that above algorithm involves.\n\n**Step1** - Set a minimum support and confidence. This means - Since there are so many different recommendations and we have just seen 2 movies in our example. Apriori is a slow alogrithm, that goes through 100 different combinations. In our case it's 100 different movies. **We might not look at products that have a support less than 20%** we don't need to consider them because we don't want to waste time building a model for something that has a success rate of 20% on it's own.\n\n**Step2** - Take all subsets in transactions having higher support than minimum support.\n\n**Step3** - Take all rules of these subsets having higher confidence than minimum confidence.\n\n**Step4** - Sort the rules by decreasing it. - That's where the lift finally comes in. The rule with highest lift given these criteria is going to be strongest rule. This is the one we might want to look into first.","metadata":{}},{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"\"\"\"For the first time ever we are not going to use scikitlearn (sklearn) library. Unfortunately since, there is no class or\nfunctions available in sklearn library we will be using another library called apyori. This apyori library has several methods\nthat are required for recommender systems.\n\nBut, since we don't have this apyori installed, we need to first install it before we make use of it.\n\nBelow is the code snippet to install the apyori library in kaggle notebook.\"\"\"\n\n!pip install apyori","metadata":{"execution":{"iopub.status.busy":"2024-06-06T19:22:53.794204Z","iopub.execute_input":"2024-06-06T19:22:53.794752Z","iopub.status.idle":"2024-06-06T19:23:13.926547Z","shell.execute_reply.started":"2024-06-06T19:22:53.794714Z","shell.execute_reply":"2024-06-06T19:23:13.924942Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting apyori\n  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: apyori\n  Building wheel for apyori (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5954 sha256=c5eb4770d40daa3437e5746f1f3fbc36d6162c318615b84ec63aebda1a6ccad6\n  Stored in directory: /root/.cache/pip/wheels/c4/1a/79/20f55c470a50bb3702a8cb7c94d8ada15573538c7f4baebe2d\nSuccessfully built apyori\nInstalling collected packages: apyori\nSuccessfully installed apyori-1.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-06T19:23:13.929803Z","iopub.execute_input":"2024-06-06T19:23:13.930352Z","iopub.status.idle":"2024-06-06T19:23:15.229316Z","shell.execute_reply.started":"2024-06-06T19:23:13.930294Z","shell.execute_reply":"2024-06-06T19:23:15.227673Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Importing dataset","metadata":{}},{"cell_type":"code","source":"\"\"\"Before fetching or importing dataset, keenly observe the data from excel. It doesn't contain column headers.\nSo, we need to specifically mention the pandas dataframe with an attribute called header and value as 'None'. This will help to\nconsider the first line of data into account. If not explicitly mentioned, it will ignore the first line of data.\"\"\"\n\ndf = pd.read_csv('/kaggle/input/market-basket-analysis/Market_Basket_Optimisation.csv',header=None)\n\n\"\"\"Now, we will use a function called apriori after importing from apyori module. And this apriori module expects the data to be\nin a list format and not in pandas dataframe format.\n\nSo, we need to finetune the format of data that is available in the form of pandas dataframe. We will change the format to list.\nList of transactions.\n\nWe will initialize an empty list as data and then append it later after looping each and every data (rows & columns) in for loop.\n\nNotice that we use 2 loops, one for fetching row values and the other loop for fetching column values. Also, we need to specify the\nrange as 7501 since the dataset contains 7500 rows and the python upper bound ignores the last value. hence 7501.\n\nNow comes the next for loop for fetching column values(j).\n\nIf you see carefully, we would used list comprehension which is the single row for loop execution.hence the [].\n\nNext is the format of df.values[i,j]. It's simply the dataframe values that we try to fetch rows and columns so what within\nsquare bracket.\n\nThe next important thing is, apriori will accept data only in string format. Hence the str() used in df.values[i,j]\"\"\"\n\ndata = []\nfor i in range(0,7501):\n    data.append([str(df.values[i,j]) for j in range(0,20)])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T19:23:15.230773Z","iopub.execute_input":"2024-06-06T19:23:15.231439Z","iopub.status.idle":"2024-06-06T19:23:15.903675Z","shell.execute_reply.started":"2024-06-06T19:23:15.231388Z","shell.execute_reply":"2024-06-06T19:23:15.902233Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Training the Apriori model on dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-06T15:19:44.378629Z","iopub.execute_input":"2024-06-06T15:19:44.379025Z","iopub.status.idle":"2024-06-06T15:19:44.426602Z","shell.execute_reply.started":"2024-06-06T15:19:44.378994Z","shell.execute_reply":"2024-06-06T15:19:44.425365Z"}}},{"cell_type":"code","source":"\"\"\"apriori function will return the rules. It will both train the apriori model and also return the rules with different supports,\nconfidences and lifts.\n\napriori function will take parameters such as datasets on which we are going to apply the apriori model. the name of the parameter is\ntransactions and the value for that is the data list which we created.\n\nThe next parameter is min_support. This is the support. We set the value for this is with minimum support value as there is a\nsupport for each rule and not to compute all the rules but atleast the rules with some certain relevance. The value is decided\npurely based on requirement. Here we need one product on left hand side of rule and the other product/element on the right hand\nside of rule. We want this products to be appeared for a minimum amount of time which is what exactly the support is. So, we consider\n3 times to be appeared for these products daily. Since the 7501 products are recorded per week, we multiply this 3 times by 7 and the\ntotal divided by 7501. ((3*7)/21 = 0.0027 rounded off to 0.003). This simply means, the product in the rules should appear 0.3% times\nof the time.\n\nThe next paramter is min_confidence. The value for this min_confidence is done using the thumb rule which is 0.8. But this value is\nway too high because 0.8 means, it should be 80% correct and since we have very few rules, we choose here as 0.2 Choosing this value\nagain depends based on business requirement. This again means for each product A in left hand side of rules, we will have product B\nin right hand side atleast 20%\n\nThe next parameter is min_lift. The value of min_lift should atleast be 3. Anything below that will not make the rule to be relevant.\nThis is again rule of thumb and based on the experience.\n\nThe next parameter is min_length which is actually the minimum no.of elements we want in our rule left or right. Since we need only\n2 products at the end. One on the left hand side of rule and the other is right hand side of rule, the value is 2.\n\nThe next parameter is max_length which is actually the maximum no.of elements we want in our rule left or right. Since we need only\n2 products at the end. One on the left hand side of rule and the other is right hand side of rule, the value is 2.\n\nFor example, if the rule or to find the deals for buy 2 and get 1 free, then the min_length=3 and max_length=3\"\"\"\n\nfrom apyori import apriori\nrules = apriori(transactions = data, min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2, max_length = 2)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T19:23:15.906184Z","iopub.execute_input":"2024-06-06T19:23:15.906592Z","iopub.status.idle":"2024-06-06T19:23:15.918922Z","shell.execute_reply.started":"2024-06-06T19:23:15.906556Z","shell.execute_reply":"2024-06-06T19:23:15.917627Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Displaying the first results coming out directly from the output of apriori function\n\nHere we will see which are going to be best deals - buy one product and get another for free.","metadata":{}},{"cell_type":"code","source":"\"\"\"Below are the list of rules that we get following the above criteria.\n\nFor instance, items_base is the product on left hand side and the items_add is the product on right hand side. If customer buys\nlight cream, then there is a 29% confidence that the same customer buy chicken.\"\"\"\n\nresults = list(rules)\nresults","metadata":{"execution":{"iopub.status.busy":"2024-06-06T19:27:14.117238Z","iopub.execute_input":"2024-06-06T19:27:14.117806Z","iopub.status.idle":"2024-06-06T19:27:14.128637Z","shell.execute_reply.started":"2024-06-06T19:27:14.117762Z","shell.execute_reply":"2024-06-06T19:27:14.126952Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[RelationRecord(items=frozenset({'light cream', 'chicken'}), support=0.004532728969470737, ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'chicken'}), confidence=0.29059829059829057, lift=4.84395061728395)]),\n RelationRecord(items=frozenset({'escalope', 'mushroom cream sauce'}), support=0.005732568990801226, ordered_statistics=[OrderedStatistic(items_base=frozenset({'mushroom cream sauce'}), items_add=frozenset({'escalope'}), confidence=0.3006993006993007, lift=3.790832696715049)]),\n RelationRecord(items=frozenset({'escalope', 'pasta'}), support=0.005865884548726837, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'escalope'}), confidence=0.3728813559322034, lift=4.700811850163794)]),\n RelationRecord(items=frozenset({'honey', 'fromage blanc'}), support=0.003332888948140248, ordered_statistics=[OrderedStatistic(items_base=frozenset({'fromage blanc'}), items_add=frozenset({'honey'}), confidence=0.2450980392156863, lift=5.164270764485569)]),\n RelationRecord(items=frozenset({'ground beef', 'herb & pepper'}), support=0.015997866951073192, ordered_statistics=[OrderedStatistic(items_base=frozenset({'herb & pepper'}), items_add=frozenset({'ground beef'}), confidence=0.3234501347708895, lift=3.2919938411349285)]),\n RelationRecord(items=frozenset({'ground beef', 'tomato sauce'}), support=0.005332622317024397, ordered_statistics=[OrderedStatistic(items_base=frozenset({'tomato sauce'}), items_add=frozenset({'ground beef'}), confidence=0.3773584905660377, lift=3.840659481324083)]),\n RelationRecord(items=frozenset({'light cream', 'olive oil'}), support=0.003199573390214638, ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'olive oil'}), confidence=0.20512820512820515, lift=3.1147098515519573)]),\n RelationRecord(items=frozenset({'whole wheat pasta', 'olive oil'}), support=0.007998933475536596, ordered_statistics=[OrderedStatistic(items_base=frozenset({'whole wheat pasta'}), items_add=frozenset({'olive oil'}), confidence=0.2714932126696833, lift=4.122410097642296)]),\n RelationRecord(items=frozenset({'shrimp', 'pasta'}), support=0.005065991201173177, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'shrimp'}), confidence=0.3220338983050847, lift=4.506672147735896)])]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Putting the results well organized into a Pandas DataFrame\n\nSince the output of the rule is very clumsy and has so many drags from left to right, there is a code snippet that helps greatly to see the data with hassle-free. This is a well organized into a pandas data frame.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}