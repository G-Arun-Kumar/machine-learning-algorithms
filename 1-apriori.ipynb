{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8617792,"sourceType":"datasetVersion","datasetId":5158113}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Association Rule Learning Intuition\n\n**'People who bought also bought'**. We would have come accross this statement or information when we buy in e-commerce websites like Flipkart or amazon. Yes. we are going to see today a topic about **recommender systems**. It's called as **association rule learning**.\n\nWe will see this via. a story.\n\nA **convenience store** did some analytics around the products that people were purchasing. They analyzed thousands and thousands and thousands of products. **Surprisingly, a peculiar commanilities between two different products** are found.\nThey are **diapers & beers**. Very peculiar ain't it?..\n\n**Deep into the story** - The husbands who are out of work and on their return to home, the wives calls them to buy diapers when they come home. And husbands after buying the diapers, they tend to buy beers before they move on to billing. This is the reason for these two products to get sold more.\n\nSo, In short, this algorithm helps to give the rule to buy two things with high statistical value. The products if bought together, will give good sales to business person.\n\nIn other words, it helps to identify the two best products that can be bought together using the rule of statistical approch and not just with speculation. business people will use criteria to increase sales of a product or do market by giving the ads to motivate the customer to buy this product.\n\n**People who bought something also bought something, people who watched also watched something, people who did something also did something** anything could be.\n\nAnd this ideally shouldn't stop **recommending with one other product alone. It can also use more than one. It can be three or four or five and so on**.\n\nThere are many types of algorithms available on association rule learning. Of which we will see two main types. They are,\n\n1. Apriori\n\n2. Eclat","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Apriori Intuition\n\nThere are some potential rules to recommend a product.\nApriori comes in three parts. They are,\n\n1. Support\n\n2. Confidence\n\n3. Lift\n\nLet's see everything in detail. The below diagram depicts the users who watched certain movies. There are people who watched movies1,2,3,4. There are people who watched both movies 1 and 4. There are people who watched both movies 1 and 3.\nPeople who both 2 and 4. People who watched 1 and 2 and so on and on and on... there are several combinations like this.\nSo, to apply the rule to recommend viewers to buy the other movie, the above algorithm is applied.\n\n**Support** - It's very similar to naive bayes algorithm. It is used for **movie recommendation**. **Support for movie M** is defined as,\n\n**Support(M) = No. of user watchlist containing M / Total no. of users.**\n\nThe above statement is as simple as the no. of users who watched a particular movie divided by the total no. of users.\n\n**Confidence(M) = No. of users watchlist containing M1 and M2 / No. of users watchlist containing M1**.\n\nThe above statement is nothing but, if suppose a movie M1 is watched by 50 users. And the same 50 users also watched movie M2 is 20. Then **confidence** is 20/50 = 2.5\n\n**Lift(M1->M2) = Confidence(M1->M2) / Support(M2)**\n\nThe above statement clearly defines. It's just the confidence/support.\n\nLet's see the step by step approach that above algorithm involves.\n\n**Step1** - Set a minimum support and confidence. This means - Since there are so many different recommendations and we have just seen 2 movies in our example. Apriori is a slow alogrithm, that goes through 100 different combinations. In our case it's 100 different movies. **We might not look at products that have a support less than 20%** we don't need to consider them because we don't want to waste time building a model for something that has a success rate of 20% on it's own.\n\n**Step2** - Take all subsets in transactions having higher support than minimum support.\n\n**Step3** - Take all rules of these subsets having higher confidence than minimum confidence.\n\n**Step4** - Sort the rules by decreasing it. - That's where the lift finally comes in. The rule with highest lift given these criteria is going to be strongest rule. This is the one we might want to look into first.","metadata":{}},{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"\"\"\"For the first time ever we are not going to use scikitlearn (sklearn) library. Unfortunately since, there is no class or\nfunctions available in sklearn library we will be using another library called apyori. This apyori library has several methods\nthat are required for recommender systems.\n\nBut, since we don't have this apyori installed, we need to first install it before we make use of it.\n\nBelow is the code snippet to install the apyori library in kaggle notebook.\"\"\"\n\n!pip install apyori","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:34:39.947815Z","iopub.execute_input":"2024-06-06T14:34:39.948523Z","iopub.status.idle":"2024-06-06T14:34:59.296849Z","shell.execute_reply.started":"2024-06-06T14:34:39.948484Z","shell.execute_reply":"2024-06-06T14:34:59.295373Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting apyori\n  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: apyori\n  Building wheel for apyori (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5954 sha256=6045e5670cd251063b5e8d9330f227806c1d3a301fa349d72cdd0f45b3ccdb8f\n  Stored in directory: /root/.cache/pip/wheels/c4/1a/79/20f55c470a50bb3702a8cb7c94d8ada15573538c7f4baebe2d\nSuccessfully built apyori\nInstalling collected packages: apyori\nSuccessfully installed apyori-1.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-06T14:28:28.002418Z","iopub.execute_input":"2024-06-06T14:28:28.002819Z","iopub.status.idle":"2024-06-06T14:28:29.267108Z","shell.execute_reply.started":"2024-06-06T14:28:28.002787Z","shell.execute_reply":"2024-06-06T14:28:29.265926Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Importing dataset","metadata":{}},{"cell_type":"code","source":"\"\"\"Before fetching or importing dataset, keenly observe the data from excel. It doesn't contain column headers.\nSo, we need to specifically mention the pandas dataframe with an attribute called header and value as 'None'. This will help to\nconsider the first line of data into account. If not explicitly mentioned, it will ignore the first line of data.\"\"\"\n\ndf = pd.read_csv('/kaggle/input/market-basket-analysis/Market_Basket_Optimisation.csv',header=None)\n\n\"\"\"Now, we will use a function called apriori after importing from apyori module. And this apriori module expects the data to be\nin a list format and not in pandas dataframe format.\n\nSo, we need to finetune the format of data that is available in the form of pandas dataframe. We will change the format to list.\nList of transactions.\n\nWe will initialize an empty list as data and then append it later after looping each and every data (rows & columns) in for loop.\n\nNotice that we use 2 loops, one for fetching row values and the other loop for fetching column values. Also, we need to specify the\nrange as 7501 since the dataset contains 7500 rows and the python upper bound ignores the last value. hence 7501.\n\nNow comes the next for loop for fetching column values(j).\n\nIf you see carefully, we would used list comprehension which is the single row for loop execution.hence the [].\n\nNext is the format of df.values[i,j]. It's simply the dataframe values that we try to fetch rows and columns so what within\nsquare bracket.\n\nThe next important thing is, apriori will accept data only in string format. Hence the str() used in df.values[i,j]\"\"\"\n\ndata = []\nfor i in range(0,7501):\n    data.append([str(df.values[i,j]) for j in range(0,20)])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T15:19:41.054334Z","iopub.execute_input":"2024-06-06T15:19:41.054753Z","iopub.status.idle":"2024-06-06T15:19:41.700530Z","shell.execute_reply.started":"2024-06-06T15:19:41.054724Z","shell.execute_reply":"2024-06-06T15:19:41.699458Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Training the Apriori model on dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-06T15:19:44.378629Z","iopub.execute_input":"2024-06-06T15:19:44.379025Z","iopub.status.idle":"2024-06-06T15:19:44.426602Z","shell.execute_reply.started":"2024-06-06T15:19:44.378994Z","shell.execute_reply":"2024-06-06T15:19:44.425365Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}